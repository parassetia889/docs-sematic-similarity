{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/parassetia889/docs-sematic-similarity/blob/main/similarity.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "POjpL0moQbV2"
      },
      "outputs": [],
      "source": [
        "!pip install sentence-transformers\n",
        "!pip install -U sentence-transformers\n",
        "!pip install PyPDF2\n",
        "!pip install pandas\n",
        "!pip install numpy\n",
        "!pip install xlrd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PyZlgcm8207R"
      },
      "outputs": [],
      "source": [
        "import PyPDF2\n",
        "import pandas as pd\n",
        "import time\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def extract_content(file_path, format):\n",
        "    if format == \"pdf\":\n",
        "        with open(file_path, 'rb') as file:\n",
        "            reader = PyPDF2.PdfReader(file)\n",
        "            text = \"\"\n",
        "            for page_num in range(len(reader.pages)):\n",
        "                page = reader.pages[page_num]\n",
        "                text += page.extract_text()\n",
        "        return text\n",
        "    elif format == \"txt\":\n",
        "        with open(file_path, 'r') as file:\n",
        "            return file.read()\n",
        "    else:\n",
        "        print(\"format : \", format)\n",
        "        raise ValueError(f\"Unsupported file format: {format}\")\n",
        "\n",
        "\n",
        "\n",
        "def split_text_into_chunks(text, chunk_size=200):\n",
        "    chunks = []\n",
        "    for i in range(0, len(text), chunk_size):\n",
        "        chunks.append(text[i:i + chunk_size])\n",
        "    return chunks\n",
        "\n",
        "\n",
        "def encode_and_combine_chunks(chunks, model):\n",
        "    chunk_embeddings = model.encode(chunks)\n",
        "    combined_embedding = np.mean(chunk_embeddings, axis=0)\n",
        "    return combined_embedding\n",
        "\n",
        "\n",
        "def compare_documents(file1_path, file2_path, chunk_size=100):\n",
        "    start_time = time.time()\n",
        "\n",
        "    model = SentenceTransformer(\"paraphrase-distilroberta-base-v2\")\n",
        "\n",
        "    # Other models to be used\n",
        "    # model = SentenceTransformer(\"sentence-transformers/msmarco-distilbert-base-v2\")\n",
        "    # model = SentenceTransformer(\"all-mpnet-base-v2\")\n",
        "    # model = SentenceTransformer(\"BAAI/bge-base-en-v1.5\")\n",
        "\n",
        "    format = file1_path.split(\".\")[1]\n",
        "    doc1_content = extract_content(file1_path, format)\n",
        "    doc2_content = extract_content(file2_path, format)\n",
        "\n",
        "\n",
        "    # Split text into chunks\n",
        "    chunk1 = split_text_into_chunks(doc1_content, chunk_size)\n",
        "    chunk2 = split_text_into_chunks(doc2_content, chunk_size)\n",
        "\n",
        "    print(f\"doc1_content : {len(doc1_content)}\")\n",
        "    print(f\"doc2_content : {len(doc2_content)}\")\n",
        "\n",
        "    # Encode chunks and combine embeddings\n",
        "    content1_embedding = encode_and_combine_chunks(chunk1, model)\n",
        "    content2_embedding = encode_and_combine_chunks(chunk2, model)\n",
        "\n",
        "    # Calculate cosine similarity\n",
        "    similarity = cosine_similarity(content1_embedding.reshape(1, -1), content2_embedding.reshape(1, -1))[0][0]\n",
        "\n",
        "    similarity_percentage = round(similarity * 100, 2)\n",
        "\n",
        "    elapsed_time = time.time() - start_time\n",
        "    print(\"Time Taken: {:.4f} seconds\".format(elapsed_time))\n",
        "    return similarity_percentage\n",
        "\n",
        "file1_path = \"/content/Hist.txt\"\n",
        "file2_path = \"/content/Moby.txt\"\n",
        "print(\"Similarity Score : \", compare_documents(file1_path, file2_path), \"\\n\")\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}